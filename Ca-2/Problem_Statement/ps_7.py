import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import statsmodels.api as sm
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, export_text
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

def ps_medical_conditions(file_path):
    st.title("ðŸ¥ Medical Condition Prediction (Using OLS + Decision Tree)")

    if file_path is not None:
        df = pd.read_csv(file_path)

        # ðŸ”¹ Define Target & Features
        dependent_col = 'Medical Conditions'
        independent_cols = ['Weight', 'Height', 'Sleep', 'Drink Usage', 'Meals per day']

        X = df[independent_cols]
        y = df[dependent_col]

        # ðŸ”¹ Step 1: Perform OLS Regression
        X_ols = sm.add_constant(X)  
        ols_model = sm.OLS(y, X_ols).fit()
        significant_results = ols_model.summary2().tables[1]

        # ðŸ”¹ Step 2: Increase p-value threshold to 0.2 (instead of 0.05)
        significant_results = significant_results[significant_results['P>|t|'] < 0.2]

        # ðŸ”¹ Step 3: Ensure Features Are Always Displayed
        st.write("### ðŸ“Œ Significant Features from OLS Regression:")
        if not significant_results.empty:
            st.write(significant_results)
        else:
            st.write("âš ï¸ No significant features found (p < 0.2). Using all available features.")

        # Extract Feature Names
        significant_features = [f for f in significant_results.index if f in X.columns]

        # If No Features Found, Use All Available Features
        if not significant_features:
            significant_features = independent_cols  
            st.write("âš ï¸ No significant features found. Using all features.")

        X = df[significant_features]

        # ðŸ”¹ Step 4: Train-Test Split (80-20)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

        # ðŸ”¹ Step 5: Train Decision Tree Classifier
        decision_tree = DecisionTreeClassifier(random_state=42)
        decision_tree.fit(X_train, y_train)

        # ðŸ”¹ Step 6: Model Predictions
        y_pred_dt = decision_tree.predict(X_test)

        # ðŸ”¹ Step 7: Evaluate Model Performance
        dt_accuracy = accuracy_score(y_test, y_pred_dt)

        st.write("### ðŸ“Š Model Performance")
        st.write(f"ðŸ”¹ **Decision Tree Accuracy:** {dt_accuracy:.4f}")

        # ðŸ”¥ Confusion Matrix
        st.write("### ðŸ”¥ Confusion Matrix")
        cm = confusion_matrix(y_test, y_pred_dt)
        plt.figure(figsize=(5, 4))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', xticklabels=["No Medical Condition", "Has Medical Condition"], 
                    yticklabels=["No Medical Condition", "Has Medical Condition"])
        plt.xlabel("Predicted")
        plt.ylabel("Actual")
        st.pyplot(plt)

        # ðŸ”¥ Classification Report
        st.write("### ðŸ“Š Classification Report")
        st.text(classification_report(y_test, y_pred_dt))

        # ðŸ”¥ Display Decision Tree Structure
        st.write("### ðŸŒ³ Decision Tree Structure")
        tree_rules = export_text(decision_tree, feature_names=significant_features)
        st.text(tree_rules)

        # ðŸŽ¯ User Prediction
        st.write("### ðŸŽ¯ Predict Medical Condition")
        user_data = []
        for feature in significant_features:
            value = st.number_input(f"ðŸ“Œ {feature}", value=0.0)
            user_data.append(value)

        if st.button("ðŸš€ Predict"):
            user_data_df = pd.DataFrame([user_data], columns=significant_features)
            user_prediction_dt = decision_tree.predict(user_data_df)[0]
            prediction_label = "âœ… No Medical Condition" if user_prediction_dt == 0 else "âš ï¸ Has Medical Condition"
            st.write(f"### ðŸ”® Prediction: **{prediction_label}**")
